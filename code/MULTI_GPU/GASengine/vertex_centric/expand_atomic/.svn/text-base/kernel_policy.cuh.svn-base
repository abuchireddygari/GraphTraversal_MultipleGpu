/******************************************************************************
 * 
 * Copyright 2010-2012 Duane Merrill
 * 
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License. 
 * 
 * For more information, see our Google Code project site: 
 * http://code.google.com/p/back40computing/
 * 
 ******************************************************************************/

/*THIS FILE HAS BEEN MODIFIED FROM THE ORIGINAL*/

/**
Copyright 2013-2014 SYSTAP, LLC.  http://www.systap.com

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

This work was (partially) funded by the DARPA XDATA program under
AFRL Contract #FA8750-13-C-0002.

This material is based upon work supported by the Defense Advanced
Research Projects Agency (DARPA) under Contract No. D14PC00029.
*/

#pragma once

#include <b40c/util/basic_utils.cuh>
#include <b40c/util/cuda_properties.cuh>
#include <b40c/util/cta_work_distribution.cuh>
#include <b40c/util/soa_tuple.cuh>
#include <b40c/util/srts_grid.cuh>
#include <b40c/util/srts_soa_details.cuh>
#include <b40c/util/io/modified_load.cuh>
#include <b40c/util/io/modified_store.cuh>
#include <b40c/util/operators.cuh>

using namespace b40c;
using namespace graph;

namespace GASengine
{
  namespace vertex_centric
  {
    namespace expand_atomic
    {

      template<
          typename Program,
          // ProblemType type parameters
          typename _ProblemType,				// BFS problem type (e.g., b40c::graph::bfs::ProblemType)

          // Machine parameters
          int _CUDA_ARCH,						// CUDA SM architecture to generate code for

          // Behavioral control parameters
          bool _INSTRUMENT,					// Whether or not we want instrumentation logic generated

          // Tunable parameters
          int _MIN_CTA_OCCUPANCY,												// Lower bound on number of CTAs to have resident per SM (influences per-CTA smem cache sizes and register allocation/spills)
          int _LOG_THREADS,													// Number of threads per CTA (log)
          int _LOG_LOAD_VEC_SIZE,												// Number of incoming frontier vertex-ids to dequeue in a single load (log)
          int _LOG_LOADS_PER_TILE,											// Number of such loads that constitute a tile of incoming frontier vertex-ids (log)
          int _LOG_RAKING_THREADS,											// Number of raking threads to use for prefix sum (log), range [5, LOG_THREADS]
          util::io::ld::CacheModifier _QUEUE_READ_MODIFIER,	// Load instruction cache-modifier for reading incoming frontier vertex-ids. Valid on SM2.0 or newer, where util::io::ld::cg is req'd for fused-iteration implementations incorporating software global barriers.
          util::io::ld::CacheModifier _COLUMN_READ_MODIFIER,					// Load instruction cache-modifier for reading CSR column-indices
          util::io::ld::CacheModifier _EDGE_VALUES_READ_MODIFIER,             // Load instruction cache-modifier for reading edge values
          util::io::ld::CacheModifier _ROW_OFFSET_ALIGNED_READ_MODIFIER,		// Load instruction cache-modifier for reading CSR row-offsets (when 8-byte aligned)
          util::io::ld::CacheModifier _ROW_OFFSET_UNALIGNED_READ_MODIFIER,	// Load instruction cache-modifier for reading CSR row-offsets (when 4-byte aligned)
          util::io::st::CacheModifier _QUEUE_WRITE_MODIFIER,// Store instruction cache-modifier for writing outgoign frontier vertex-ids. Valid on SM2.0 or newer, where util::io::st::cg is req'd for fused-iteration implementations incorporating software global barriers.
          bool _WORK_STEALING,												// Whether or not incoming frontier tiles are distributed via work-stealing or by even-share.
          int _WARP_GATHER_THRESHOLD,	// Adjacency-list length above which we expand an that list using coarser-grained warp-based cooperative expansion (below which we perform fine-grained scan-based expansion)
          int _CTA_GATHER_THRESHOLD,		// Adjacency-list length above which we expand an that list using coarsest-grained CTA-based cooperative expansion (below which we perform warp-based expansion)
          int _LOG_SCHEDULE_GRANULARITY>										// The scheduling granularity of incoming frontier tiles (for even-share work distribution only) (log)

      struct KernelPolicy: _ProblemType
      {
        //---------------------------------------------------------------------
        // Constants and typedefs
        //---------------------------------------------------------------------

        typedef _ProblemType ProblemType;
        typedef typename ProblemType::VertexId VertexId;
        typedef typename ProblemType::SizeT SizeT;
        typedef typename ProblemType::EValue EValue;

        static const util::io::ld::CacheModifier QUEUE_READ_MODIFIER = _QUEUE_READ_MODIFIER;
        static const util::io::ld::CacheModifier COLUMN_READ_MODIFIER = _COLUMN_READ_MODIFIER;
        static const util::io::ld::CacheModifier EDGE_VALUES_READ_MODIFIER = _EDGE_VALUES_READ_MODIFIER;
        static const util::io::ld::CacheModifier ROW_OFFSET_ALIGNED_READ_MODIFIER = _ROW_OFFSET_ALIGNED_READ_MODIFIER;
        static const util::io::ld::CacheModifier ROW_OFFSET_UNALIGNED_READ_MODIFIER = _ROW_OFFSET_UNALIGNED_READ_MODIFIER;
        static const util::io::st::CacheModifier QUEUE_WRITE_MODIFIER = _QUEUE_WRITE_MODIFIER;

        enum
        {

          CUDA_ARCH = _CUDA_ARCH,
          INSTRUMENT = _INSTRUMENT,

          LOG_THREADS = _LOG_THREADS,
          THREADS = 1 << LOG_THREADS,

          LOG_LOAD_VEC_SIZE = _LOG_LOAD_VEC_SIZE,
          LOAD_VEC_SIZE = 1 << LOG_LOAD_VEC_SIZE,

          LOG_LOADS_PER_TILE = _LOG_LOADS_PER_TILE,
          LOADS_PER_TILE = 1 << LOG_LOADS_PER_TILE,

          LOG_LOAD_STRIDE = LOG_THREADS + LOG_LOAD_VEC_SIZE,
          LOAD_STRIDE = 1 << LOG_LOAD_STRIDE,

          LOG_RAKING_THREADS = _LOG_RAKING_THREADS,
          RAKING_THREADS = 1 << LOG_RAKING_THREADS,

          LOG_WARPS = LOG_THREADS - B40C_LOG_WARP_THREADS_BFS(CUDA_ARCH),
          WARPS = 1 << LOG_WARPS,

          LOG_TILE_ELEMENTS_PER_THREAD = LOG_LOAD_VEC_SIZE + LOG_LOADS_PER_TILE,
          TILE_ELEMENTS_PER_THREAD = 1 << LOG_TILE_ELEMENTS_PER_THREAD,

          LOG_TILE_ELEMENTS = LOG_TILE_ELEMENTS_PER_THREAD + LOG_THREADS,
          TILE_ELEMENTS = 1 << LOG_TILE_ELEMENTS,

          LOG_SCHEDULE_GRANULARITY = _LOG_SCHEDULE_GRANULARITY,
          SCHEDULE_GRANULARITY = 1 << LOG_SCHEDULE_GRANULARITY,

          WORK_STEALING = _WORK_STEALING,
          WARP_GATHER_THRESHOLD = _WARP_GATHER_THRESHOLD,
          CTA_GATHER_THRESHOLD = _CTA_GATHER_THRESHOLD,
        };

        // Prefix sum raking grid for coarse-grained expansion allocations
        typedef util::RakingGrid<
            CUDA_ARCH,
            SizeT,									// Partial type
            LOG_THREADS,							// Depositing threads (the CTA size)
            LOG_LOADS_PER_TILE,						// Lanes (the number of loads)
            LOG_RAKING_THREADS,						// Raking threads
            true>									// There are prefix dependences between lanes
        CoarseGrid;

        // Prefix sum raking grid for fine-grained expansion allocations
        typedef util::RakingGrid<
            CUDA_ARCH,
            SizeT,									// Partial type
            LOG_THREADS,							// Depositing threads (the CTA size)
            LOG_LOADS_PER_TILE,						// Lanes (the number of loads)
            LOG_RAKING_THREADS,						// Raking threads
            true>									// There are prefix dependences between lanes
        FineGrid;

        // Type for (coarse-partial, fine-partial) tuples
        typedef util::Tuple<SizeT, SizeT> TileTuple;

        // Structure-of-array (SOA) prefix sum raking grid type (CoarseGrid, FineGrid)
        typedef util::Tuple<
            CoarseGrid,
            FineGrid> RakingGridTuple;

        // Operational details type for SOA raking grid
        typedef util::RakingSoaDetails<
            TileTuple,
            RakingGridTuple> RakingSoaDetails;

        // Prefix sum tuple operator for SOA raking grid
        struct SoaScanOp
        {
          enum
          {
            IDENTITY_STRIDES = true,			// There is an "identity" region of warpscan storage exists for strides to index into
          };

          // SOA scan operator
          __device__  __forceinline__ TileTuple operator()(
              const TileTuple &first,
              const TileTuple &second)
          {
            return TileTuple(first.t0 + second.t0, first.t1 + second.t1);
          }

          // SOA identity operator
          __device__  __forceinline__ TileTuple operator()()
          {
            return TileTuple(0, 0);
          }
        };

        /**
         * Shared memory storage type for the CTA
         */
        struct SmemStorage
        {
          // Persistent shared state for the CTA
          struct State
          {

            // Type describing four shared memory channels per warp for intra-warp communication
            typedef SizeT WarpComm[WARPS][4];

            // Whether or not we overflowed our outgoing frontier
            bool overflowed;

            // Shared work-processing limits
            util::CtaWorkDistribution<SizeT> work_decomposition;

            // Shared memory channels for intra-warp communication
            volatile WarpComm warp_comm;
            int cta_comm;

            // Storage for scanning local contract-expand ranks
            SizeT coarse_warpscan[2][B40C_WARP_THREADS_BFS(CUDA_ARCH)];
            SizeT fine_warpscan[2][B40C_WARP_THREADS_BFS(CUDA_ARCH)];

            // Enqueue offset for neighbors of the current tile
            SizeT coarse_enqueue_offset;
            SizeT fine_enqueue_offset;

          } state;

          enum
          {
            // Amount of storage we can use for hashing scratch space under target occupancy
            MAX_SCRATCH_BYTES_PER_CTA = (B40C_SMEM_BYTES(CUDA_ARCH) / _MIN_CTA_OCCUPANCY)
                - sizeof(State)
                - 128,											// Fudge-factor to guarantee occupancy

//			MAX_SCRATCH_BYTES_PER_CTA		= (B40C_SMEM_BYTES(CUDA_ARCH) - sizeof(State) - 128 ) / _MIN_CTA_OCCUPANCY,

            SCRATCH_ELEMENT_SIZE = sizeof(SizeT) + sizeof(typename Program::MiscType),			        // Need both gather offset and predecessor

            GATHER_ELEMENTS = MAX_SCRATCH_BYTES_PER_CTA / SCRATCH_ELEMENT_SIZE,
            PARENT_ELEMENTS = GATHER_ELEMENTS,
          };

          union
          {
            // Raking elements
            struct
            {
              SizeT coarse_raking_elements[CoarseGrid::TOTAL_RAKING_ELEMENTS];
              SizeT fine_raking_elements[FineGrid::TOTAL_RAKING_ELEMENTS];
            };

            // Scratch elements
            struct
            {
              SizeT gather_offsets[GATHER_ELEMENTS];
              typename Program::MiscType gather_predecessors[PARENT_ELEMENTS];
            };
          };

        };

        enum
        {
          THREAD_OCCUPANCY = B40C_SM_THREADS(CUDA_ARCH) >> LOG_THREADS,
          SMEM_OCCUPANCY = B40C_SMEM_BYTES(CUDA_ARCH) / sizeof(SmemStorage),
          CTA_OCCUPANCY = B40C_MIN(_MIN_CTA_OCCUPANCY, B40C_MIN(B40C_SM_CTAS(CUDA_ARCH), B40C_MIN(THREAD_OCCUPANCY, SMEM_OCCUPANCY))),

          VALID = (CTA_OCCUPANCY > 0),
        };
      };

    } // namespace expand_atomic
  } // namespace vertex_centric
} // namespace GASengine

